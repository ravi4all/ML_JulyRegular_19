{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import nltk\n",
    "# 1. Tokenization\n",
    "from nltk.tokenize import word_tokenize\n",
    "# 2. Remove Stopwords\n",
    "from nltk.corpus import stopwords\n",
    "# 3. Stemming/Lemmatizer\n",
    "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
    "# 4. Count Vectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "document = [\n",
    "    \"Indian cricket team played well in world cup.\",\n",
    "    \"Virat Kohli is good captain but rohit sharma also proved to be a good captain.\",\n",
    "    \"Now Indian cricket board will also look for replacement of ms dhoni\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Indian', 'cricket', 'team', 'played', 'well', 'in', 'world', 'cup', '.']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_tokenize(document[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(document)):\n",
    "    document[i] = word_tokenize(document[i].lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['virat', 'kohli', 'is', 'good', 'captain', 'but', 'rohit', 'sharma', 'also', 'proved', 'to', 'be', 'a', 'good', 'captain', '.']\n"
     ]
    }
   ],
   "source": [
    "print(document[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordsList = []\n",
    "s_word = stopwords.words(\"english\")\n",
    "s_word.extend([\".\",\"also\"])\n",
    "for tokenList in document:\n",
    "    words = []\n",
    "    for token in tokenList:\n",
    "        if token not in s_word:\n",
    "            words.append(token)\n",
    "    wordsList.append(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['indian', 'cricket', 'team', 'played', 'well', 'world', 'cup'],\n",
       " ['virat',\n",
       "  'kohli',\n",
       "  'good',\n",
       "  'captain',\n",
       "  'rohit',\n",
       "  'sharma',\n",
       "  'proved',\n",
       "  'good',\n",
       "  'captain'],\n",
       " ['indian', 'cricket', 'board', 'look', 'replacement', 'ms', 'dhoni']]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wordsList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ps = PorterStemmer()\n",
    "wnet = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(wordsList)):\n",
    "    for j in range(len(wordsList[i])):\n",
    "#         print(ps.stem(wordsList[i][j]))\n",
    "#         print(wnet.lemmatize(wordsList[i][j],pos='v'))\n",
    "        wordsList[i][j] = wnet.lemmatize(wordsList[i][j],pos='v')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['indian', 'cricket', 'team', 'play', 'well', 'world', 'cup'],\n",
       " ['virat',\n",
       "  'kohli',\n",
       "  'good',\n",
       "  'captain',\n",
       "  'rohit',\n",
       "  'sharma',\n",
       "  'prove',\n",
       "  'good',\n",
       "  'captain'],\n",
       " ['indian', 'cricket', 'board', 'look', 'replacement', 'ms', 'dhoni']]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wordsList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(wordsList)):\n",
    "    wordsList[i] = ' '.join(wordsList[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['indian cricket team play well world cup',\n",
       " 'virat kohli good captain rohit sharma prove good captain',\n",
       " 'indian cricket board look replacement ms dhoni']"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wordsList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = CountVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "        strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "        tokenizer=None, vocabulary=None)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv.fit(wordsList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'indian': 6, 'cricket': 2, 'team': 15, 'play': 10, 'well': 17, 'world': 18, 'cup': 3, 'virat': 16, 'kohli': 7, 'good': 5, 'captain': 1, 'rohit': 13, 'sharma': 14, 'prove': 11, 'board': 0, 'look': 8, 'replacement': 12, 'ms': 9, 'dhoni': 4}\n"
     ]
    }
   ],
   "source": [
    "print(cv.vocabulary_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "vect = cv.transform(wordsList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<3x19 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 21 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1],\n",
       "       [0, 2, 0, 0, 0, 2, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0],\n",
       "       [1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0]],\n",
       "      dtype=int64)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vect.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
